package org.usfirst.frc.team2429.spartan2017.imaging;

import org.usfirst.frc.team2429.spartan2017.Robot;
import org.usfirst.frc.team2429.spartan2017.RobotMap;

import java.util.ArrayList;
import java.util.Collections;
import java.util.Comparator;
import java.util.List;
import java.util.Iterator;
import edu.wpi.first.wpilibj.Timer;
import edu.wpi.first.wpilibj.command.Command;
import edu.wpi.first.wpilibj.vision.VisionPipeline;

import org.opencv.core.*;
import org.opencv.imgproc.*;

/**
* ImageCaptureAndProcess class.
*
* <p>An OpenCV pipeline generated by GRIP.
*
* @author GRIP
*/
public class ImageCaptureAndProcess extends Command implements VisionPipeline{

	// To run a GRIP pipeline, just copy in the whole pipeline.  Then 
	// add extends Command to the class definition
	// and copy in the regular command methods
	// finally put the process() method GRIP creates into your execute method
	// and go to town on the analysis of the final contours
	
	int iterations;
	int count;
	
    public ImageCaptureAndProcess(int iterations) {
        // Use requires() here to declare subsystem dependencies
        // eg. requires(chassis);
    	this.iterations = iterations-1;
    }
	
    public ImageCaptureAndProcess() {
        // Use requires() here to declare subsystem dependencies
        // eg. requires(chassis);
    	this.iterations = 0;
    }

    // Called just before this Command runs the first time
    protected void initialize() {
    	System.out.println("\nImageCaptureAndProcess called at: " + String.format("%.2f", Timer.getFPGATimestamp()) + "s");
    	count = 0;
    }

    // Called repeatedly when this Command is scheduled to run
    protected void execute() {
    	//keep track of how many times we've been through
    	count++;
    	// Send an image into the pipeline
    	RobotMap.cvSink.grabFrame(RobotMap.mat);
		process(RobotMap.mat);
		
		//print out everything about the contours
		System.out.println("Found " + filterContoursOutput.size() + " contours");
		
		//Sum it all up
		int targetCount = filterContoursOutput.size();
		
		if (targetCount > 1) {
			Robot.imageProcessor.targetsAcquired = true;
			
			// Remember, the comparison that returns 1 goes to the END of the array
			// We want the big ones up front
			Collections.sort(filterContoursOutput, new Comparator<MatOfPoint>() {
				  @Override public int compare(final MatOfPoint o1, final MatOfPoint o2) {
				    if (Imgproc.contourArea(o1) < Imgproc.contourArea(o2)) {
				      return 1;
				    } else if (Imgproc.contourArea(o1) > Imgproc.contourArea(o2)) {
				      return -1;
				    }  
				    return 0;
				  }
				});			
			
			List<MatOfPoint> mainTargets = filterContoursOutput.subList(0, 2);
			
			//Sort arrays left to right and write global variables based on the results of the target finding operation
			//So we want the smaller X values up front
			Collections.sort(mainTargets, new Comparator<MatOfPoint>() {
				  @Override public int compare(final MatOfPoint o1, final MatOfPoint o2) {
				    if (Imgproc.moments(o1).get_m10() / Imgproc.moments(o1).get_m00() > Imgproc.moments(o2).get_m10() / Imgproc.moments(o2).get_m00()) {
				      return 1;
				    } else if (Imgproc.moments(o1).get_m10() / Imgproc.moments(o1).get_m00() < Imgproc.moments(o2).get_m10() / Imgproc.moments(o2).get_m00()) {
				      return -1;
				    }  
				    return 0;
				  }
				});	
			
		    //Probably  better to do this with the globals on the ImageProcessor Subsystem
		    double targetAreas [] = new double[2];
		    double targetX [] = new double[2];
		    double targetY [] = new double[2];
		    double targetHeight[] = new double[2];
		    double targetWidth[] = new double[2];
		    int count=0;
		    
		    Iterator<MatOfPoint> each = mainTargets.iterator();
		    System.out.printf( "%-15s %15s %15s %15s%n", "Areas", "Center", "Height", "Width");
		    while (each.hasNext()) {
		        MatOfPoint wrapper = each.next();
		        Moments moments = Imgproc.moments(wrapper);
		        double area = Imgproc.contourArea(wrapper);
		        Point centroid = new Point();
				centroid.x = moments.get_m10() / moments.get_m00();
				centroid.y = moments.get_m01() / moments.get_m00();
				Rect rectangle = Imgproc.boundingRect(wrapper);
				targetAreas[count]= 100.0*area/(RobotMap.gearCamWidth*RobotMap.gearCamHeight);
				targetX[count]=(-1.0+ 2.0*centroid.x/RobotMap.gearCamWidth);
				targetY[count]=(-1.0+ 2.0*centroid.y/RobotMap.gearCamHeight);
				targetHeight[count] = 100.0* rectangle.height/RobotMap.gearCamHeight;
				targetWidth[count]= 100.0*rectangle.width/RobotMap.gearCamWidth;
				String centriodstring = "(" + String.format("%.2f",targetX[count]) +", "+ String.format("%.2f",targetY[count]) + ")";
				
				System.out.printf( "%-15s %15s %15s %15s%n", String.format("%.2f",targetAreas[count]), centriodstring, 
						String.format("%.2f",targetHeight[count]), String.format("%.2f",targetWidth[count]));
				count++;
				//System.out.println(area + "\t\t(" + String.format("%.1f",centroid.x) +", "+ String.format("%.1f",centroid.y) + ")\t\t" + rectangle.height +"\t\t" + rectangle.width);
		    }
		    
		    System.out.println(" ");
			//TODO: 
		    //Boolean about targets acquired, int number of targets
		    //Double arrays on the areas, locations, and heights and maybe more if we need them
		    //This will be stored in the image processing subsystem, I think.  Makes the most sense.
		    //May also want to publish to network tables so pi and RIO both look the same to debug client 
		    Robot.imageProcessor.gearTargetAreas = targetAreas;
		    Robot.imageProcessor.gearTargetX = targetX;
		    Robot.imageProcessor.gearTargetY = targetY;
		    Robot.imageProcessor.gearTargetHeights = targetHeight;
		    System.out.println("Forward distance to target: "+ String.format("%.2f",Robot.imageProcessor.getGearTargetDistance()));
		    System.out.println("Lateral distance to target: "+ String.format("%.2f",Robot.imageProcessor.getGearTargetStrafe()));
		    //Robot.imageProcessor.updateTargetAreas();
		    //System.out.println("Average areas (L/R): " + String.format("%.3f",Robot.imageProcessor.gearTargetAreaAveragesLeft) +
		    //		" / "+ String.format("%.3f",Robot.imageProcessor.gearTargetAreaAveragesRight) + " = " + 
		    //		String.format("%.3f",Robot.imageProcessor.gearTargetAreaAveragesLeft/Robot.imageProcessor.gearTargetAreaAveragesRight));
		}  // end condition on targets found

		else {
			Robot.imageProcessor.targetsAcquired = false;
			System.out.println("No valid targets acquired :( ");
			Robot.imageProcessor.gearTargetAreas = new double[] {0,0};
		    Robot.imageProcessor.gearTargetX = new double[] {0,0};
		    Robot.imageProcessor.gearTargetY = new double[] {0,0};
		    Robot.imageProcessor.gearTargetHeights = new double[] {0,0};
		    Robot.imageProcessor.gearTargetHeights = new double[] {0,0};
		} // end else on no targets found
		 //Sort on area, largest to smallest

	}

	// Make this return true when this Command no longer needs to run execute()
    protected boolean isFinished() {
        return (count > iterations);
    }

    // Called once after isFinished returns true
    protected void end() {
    	System.out.println("ImageCaptureAndProcess ended at: " + String.format("%.2f", Timer.getFPGATimestamp()) + "s");
    	
    }

    // Called when another command which requires one or more of the same
    // subsystems is scheduled to run
    protected void interrupted() {
    	System.out.println("\nImageCaptureAndProcess interrupted at: " + String.format("%.2f", Timer.getFPGATimestamp()) + "s");
    	
    }
	
	//Outputs
	private Mat blurOutput = new Mat();
	private Mat hsvThresholdOutput = new Mat();
	private ArrayList<MatOfPoint> findContoursOutput = new ArrayList<MatOfPoint>();
	private ArrayList<MatOfPoint> filterContoursOutput = new ArrayList<MatOfPoint>();

	static {
		System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
	}

	/**
	 * This is the primary method that runs the entire pipeline and updates the outputs.
	 */
	@Override	public void process(Mat source0) {
		// Step Blur0:
		Mat blurInput = source0;
		BlurType blurType = BlurType.get("Box Blur");
		double blurRadius = 5.0;
		blur(blurInput, blurType, blurRadius, blurOutput);

		// Step HSV_Threshold0:
		Mat hsvThresholdInput = blurOutput;
		double[] hsvThresholdHue = {48.0, 96.0};
		double[] hsvThresholdSaturation = {100.0, 255.0};
		double[] hsvThresholdValue = {10.0, 255.0};
		hsvThreshold(hsvThresholdInput, hsvThresholdHue, hsvThresholdSaturation, hsvThresholdValue, hsvThresholdOutput);

		// Step Find_Contours0:
		Mat findContoursInput = hsvThresholdOutput;
		boolean findContoursExternalOnly = true;
		findContours(findContoursInput, findContoursExternalOnly, findContoursOutput);

		// Step Filter_Contours0:
		ArrayList<MatOfPoint> filterContoursContours = findContoursOutput;
		double filterContoursMinArea = 100.0;
		double filterContoursMinPerimeter = 0;
		double filterContoursMinWidth = 5.0;
		double filterContoursMaxWidth = 1000;
		double filterContoursMinHeight = 5.0;
		double filterContoursMaxHeight = 1000;
		double[] filterContoursSolidity = {0, 100};
		double filterContoursMaxVertices = 1000000;
		double filterContoursMinVertices = 0;
		double filterContoursMinRatio = 0;
		double filterContoursMaxRatio = 1000;
		filterContours(filterContoursContours, filterContoursMinArea, filterContoursMinPerimeter, filterContoursMinWidth, filterContoursMaxWidth, filterContoursMinHeight, filterContoursMaxHeight, filterContoursSolidity, filterContoursMaxVertices, filterContoursMinVertices, filterContoursMinRatio, filterContoursMaxRatio, filterContoursOutput);

	}

	/**
	 * This method is a generated getter for the output of a Blur.
	 * @return Mat output from Blur.
	 */
	public Mat blurOutput() {
		return blurOutput;
	}

	/**
	 * This method is a generated getter for the output of a HSV_Threshold.
	 * @return Mat output from HSV_Threshold.
	 */
	public Mat hsvThresholdOutput() {
		return hsvThresholdOutput;
	}

	/**
	 * This method is a generated getter for the output of a Find_Contours.
	 * @return ArrayList<MatOfPoint> output from Find_Contours.
	 */
	public ArrayList<MatOfPoint> findContoursOutput() {
		return findContoursOutput;
	}

	/**
	 * This method is a generated getter for the output of a Filter_Contours.
	 * @return ArrayList<MatOfPoint> output from Filter_Contours.
	 */
	public ArrayList<MatOfPoint> filterContoursOutput() {
		return filterContoursOutput;
	}


	/**
	 * An indication of which type of filter to use for a blur.
	 * Choices are BOX, GAUSSIAN, MEDIAN, and BILATERAL
	 */
	enum BlurType{
		BOX("Box Blur"), GAUSSIAN("Gaussian Blur"), MEDIAN("Median Filter"),
			BILATERAL("Bilateral Filter");

		private final String label;

		BlurType(String label) {
			this.label = label;
		}

		public static BlurType get(String type) {
			if (BILATERAL.label.equals(type)) {
				return BILATERAL;
			}
			else if (GAUSSIAN.label.equals(type)) {
			return GAUSSIAN;
			}
			else if (MEDIAN.label.equals(type)) {
				return MEDIAN;
			}
			else {
				return BOX;
			}
		}

		@Override
		public String toString() {
			return this.label;
		}
	}

	/**
	 * Softens an image using one of several filters.
	 * @param input The image on which to perform the blur.
	 * @param type The blurType to perform.
	 * @param doubleRadius The radius for the blur.
	 * @param output The image in which to store the output.
	 */
	private void blur(Mat input, BlurType type, double doubleRadius,
		Mat output) {
		int radius = (int)(doubleRadius + 0.5);
		int kernelSize;
		switch(type){
			case BOX:
				kernelSize = 2 * radius + 1;
				Imgproc.blur(input, output, new Size(kernelSize, kernelSize));
				break;
			case GAUSSIAN:
				kernelSize = 6 * radius + 1;
				Imgproc.GaussianBlur(input,output, new Size(kernelSize, kernelSize), radius);
				break;
			case MEDIAN:
				kernelSize = 2 * radius + 1;
				Imgproc.medianBlur(input, output, kernelSize);
				break;
			case BILATERAL:
				Imgproc.bilateralFilter(input, output, -1, radius, radius);
				break;
		}
	}

	/**
	 * Segment an image based on hue, saturation, and value ranges.
	 *
	 * @param input The image on which to perform the HSL threshold.
	 * @param hue The min and max hue
	 * @param sat The min and max saturation
	 * @param val The min and max value
	 * @param output The image in which to store the output.
	 */
	private void hsvThreshold(Mat input, double[] hue, double[] sat, double[] val,
	    Mat out) {
		Imgproc.cvtColor(input, out, Imgproc.COLOR_BGR2HSV);
		Core.inRange(out, new Scalar(hue[0], sat[0], val[0]),
			new Scalar(hue[1], sat[1], val[1]), out);
	}

	/**
	 * Sets the values of pixels in a binary image to their distance to the nearest black pixel.
	 * @param input The image on which to perform the Distance Transform.
	 * @param type The Transform.
	 * @param maskSize the size of the mask.
	 * @param output The image in which to store the output.
	 */
	private void findContours(Mat input, boolean externalOnly,
		List<MatOfPoint> contours) {
		Mat hierarchy = new Mat();
		contours.clear();
		int mode;
		if (externalOnly) {
			mode = Imgproc.RETR_EXTERNAL;
		}
		else {
			mode = Imgproc.RETR_LIST;
		}
		int method = Imgproc.CHAIN_APPROX_SIMPLE;
		Imgproc.findContours(input, contours, hierarchy, mode, method);
	}


	/**
	 * Filters out contours that do not meet certain criteria.
	 * @param inputContours is the input list of contours
	 * @param output is the the output list of contours
	 * @param minArea is the minimum area of a contour that will be kept
	 * @param minPerimeter is the minimum perimeter of a contour that will be kept
	 * @param minWidth minimum width of a contour
	 * @param maxWidth maximum width
	 * @param minHeight minimum height
	 * @param maxHeight maximimum height
	 * @param Solidity the minimum and maximum solidity of a contour
	 * @param minVertexCount minimum vertex Count of the contours
	 * @param maxVertexCount maximum vertex Count
	 * @param minRatio minimum ratio of width to height
	 * @param maxRatio maximum ratio of width to height
	 */
	private void filterContours(List<MatOfPoint> inputContours, double minArea,
		double minPerimeter, double minWidth, double maxWidth, double minHeight, double
		maxHeight, double[] solidity, double maxVertexCount, double minVertexCount, double
		minRatio, double maxRatio, List<MatOfPoint> output) {
		final MatOfInt hull = new MatOfInt();
		output.clear();
		//operation
		for (int i = 0; i < inputContours.size(); i++) {
			final MatOfPoint contour = inputContours.get(i);
			final Rect bb = Imgproc.boundingRect(contour);
			if (bb.width < minWidth || bb.width > maxWidth) continue;
			if (bb.height < minHeight || bb.height > maxHeight) continue;
			final double area = Imgproc.contourArea(contour);
			if (area < minArea) continue;
			if (Imgproc.arcLength(new MatOfPoint2f(contour.toArray()), true) < minPerimeter) continue;
			Imgproc.convexHull(contour, hull);
			MatOfPoint mopHull = new MatOfPoint();
			mopHull.create((int) hull.size().height, 1, CvType.CV_32SC2);
			for (int j = 0; j < hull.size().height; j++) {
				int index = (int)hull.get(j, 0)[0];
				double[] point = new double[] { contour.get(index, 0)[0], contour.get(index, 0)[1]};
				mopHull.put(j, 0, point);
			}
			final double solid = 100 * area / Imgproc.contourArea(mopHull);
			if (solid < solidity[0] || solid > solidity[1]) continue;
			if (contour.rows() < minVertexCount || contour.rows() > maxVertexCount)	continue;
			final double ratio = bb.width / (double)bb.height;
			if (ratio < minRatio || ratio > maxRatio) continue;
			output.add(contour);
		}
	}




}

